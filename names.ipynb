{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Evaluation\n",
    "\n",
    "This document evaluates a list of American names published by the Social Security Administration.\n",
    "\n",
    "[SSA data taken from here](https://rstudio-pubs-static.s3.amazonaws.com/24678_8234c801b4134f2cb32d8077f6cd75a2.html). Phonetic dictionary from CMU Sphinx project. [Scrabble dictionary from here](https://github.com/adrielklein/scrabble-word-finder). [Biblical names from here](https://github.com/SuzanaK/biblical_dictionary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names taken out of consideration\n",
    "\n",
    "family_names = {\n",
    "    'Robert', 'Bob', 'Paula', 'Teo', 'Hannah', 'Andrew',\n",
    "    'Andy', 'Rylan', 'Jacob', 'Martha', 'Neil', 'Carol', 'Sandy',\n",
    "    'Leslie', 'Joel', 'Noah', 'Isaac', 'Benjamin', 'Ben',    \n",
    "}\n",
    "\n",
    "friend_names = {\n",
    "    'Kevin', 'Sabrina', 'Pete', 'Peter', 'Sarahana', 'Andy', 'Cap', 'Kim',\n",
    "    'Malika', 'Canaan', 'Max', 'Ellis', 'Brandon', 'Oliver', 'Polly', 'Bilal',\n",
    "}\n",
    "\n",
    "colleague_names = {\n",
    "    'Anna', 'Jaime', 'Ian', 'Sufian', 'Vedant', 'Olivier', 'Raz', 'Jenna',\n",
    "    'Whitney', 'Rachel', 'Jon', 'John', 'Racine', 'Rocio', 'Jason', 'Simon',\n",
    "    'Fiona', 'Renaud', 'Aaron', 'Sam', 'Samantha', 'Michael', 'Allan', 'Cal',\n",
    "    'Stewart' 'Ahmed', 'Arpita', 'Jonathan', 'Milo', 'Cy', 'Hera', 'Renaud',\n",
    "    'Christopher', 'Daniel', 'Stan', 'Gio', 'Anders', 'Avi', 'Lara', 'Moishe',\n",
    "    'Gregg', 'Stefan'\n",
    "}\n",
    "\n",
    "famous_people = {\n",
    "    'Adolf', 'Adolph', 'Donald',\n",
    "    'Barack', 'Bill',\n",
    "    'Michaelangelo', 'Leonardo', 'Splinter', 'Shredder', 'Krang',\n",
    "    'Lucille', 'Jesus', 'Jean Luc', 'William', 'Harry', 'Geordi',\n",
    "    'Ayn', 'Tupac', 'Oprah', 'Vader', 'Kermit',\n",
    "}\n",
    "\n",
    "block_list = {\n",
    "    'Uber', 'Nacho', 'Avis', 'Ryker', 'Jude', 'Judah', 'Jihad', 'Gaza',\n",
    "    'Jesus', 'Moses', 'Mohammad', 'Ray', 'Pansy', 'Ulysses'\n",
    "}.union(\n",
    "    family_names, friend_names, colleague_names, famous_people\n",
    ")\n",
    "\n",
    "cool_names = {\n",
    "    'Mia',\n",
    "    'Leidy',\n",
    "    'Chess',\n",
    "    'Key',\n",
    "    'Less',\n",
    "    'Vella',\n",
    "    'Ekco',\n",
    "    'Echo',\n",
    "    'Twig'\n",
    "    'Del',\n",
    "    'Eloy',\n",
    "    'Helix',\n",
    "    'Ada',\n",
    "    'Luma',\n",
    "    'Lua',\n",
    "    'Elia',\n",
    "    'Arthur',\n",
    "    'Tron',\n",
    "    'Alice',\n",
    "    'Rita',\n",
    "    'June',\n",
    "    'Lina',\n",
    "    'Amelia',\n",
    "    'Regan',\n",
    "    'Kermit',\n",
    "    'Melchizedek',\n",
    "    'Shingo',\n",
    "    'Gray',\n",
    "    'Moss',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list of all names since 1880 from the SSA dataset\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "yob_file_list = [f for f in listdir(\"ssa\") if isfile(join(\"ssa\", f)) and f.startswith(\"yob\")]\n",
    "\n",
    "import csv\n",
    "year_name_frequency = {}\n",
    "gender_year_name_frequency = {}\n",
    "gender_year_name_frequency['M'] = {}\n",
    "gender_year_name_frequency['F'] = {}\n",
    "for file_name in yob_file_list:\n",
    "    year = int(file_name[3:7])\n",
    "    year_name_frequency[year] = {}\n",
    "    gender_year_name_frequency['M'][year] = {}\n",
    "    gender_year_name_frequency['F'][year] = {}\n",
    "    with open(join(\"ssa\", file_name)) as content:\n",
    "        csvReader = csv.reader(content)\n",
    "        for row in csvReader:\n",
    "            year_name_frequency[year][row[0]] = year_name_frequency[year].get(row[0], 0) + int(row[2])\n",
    "            gender_year_name_frequency[row[1]][year][row[0]] = int(row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dictionary\n",
    "phonetic_dictionary = {}\n",
    "with open(\"cmudict/cmudict.dict\") as file:\n",
    "    for line in file:\n",
    "       list = line.split('#')[0].split()\n",
    "       phonetic_dictionary[str(list[0])] = list[1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a dictionary of english words\n",
    "# Words from https://github.com/adrielklein/scrabble-word-finder\n",
    "english_dictionary = set()\n",
    "with open(\"twl06.txt\") as file:\n",
    "    for line in file:\n",
    "       english_dictionary.add(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a dictionary of biblical names\n",
    "# Words from https://github.com/SuzanaK/biblical_dictionary\n",
    "biblical_names = set()\n",
    "with open(\"biblical_names_in_wordnet.txt\") as file:\n",
    "    for line in file:\n",
    "       biblical_names.add(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an all-time frequency map \n",
    "name_frequency = {};\n",
    "for year in year_name_frequency.keys():\n",
    "    for name in year_name_frequency[year].keys():\n",
    "        name_frequency[name] = name_frequency.get(name, 0) + year_name_frequency[year][name]\n",
    "sorted_name_frequency = sorted(name_frequency.items(), key=lambda kv: kv[1])[::-1]\n",
    "\n",
    "# Get frequency for each name by gender\n",
    "gender_name_frequency = { 'M': {}, 'F': {} }\n",
    "for gender in gender_year_name_frequency.keys():\n",
    "    for year in gender_year_name_frequency[gender].keys():\n",
    "        for name in gender_year_name_frequency[gender][year].keys():\n",
    "            gender_name_frequency[gender][name] = gender_name_frequency[gender].get(name, 0) + gender_year_name_frequency[gender][year][name]\n",
    "\n",
    "# Get a frequency rank overall\n",
    "name_rank = {};\n",
    "i = 0\n",
    "for pair in sorted_name_frequency:\n",
    "    name_rank[pair[0]] = i\n",
    "    i = i + 1\n",
    "\n",
    "# Create a map from name to a graph of frequency by year\n",
    "name_year_frequency = {};\n",
    "for year in year_name_frequency:\n",
    "    for name in year_name_frequency[year]:\n",
    "        if name not in name_year_frequency:\n",
    "            name_year_frequency[name] = {}\n",
    "        name_year_frequency[name][year] = year_name_frequency[year][name]\n",
    "\n",
    "# In what year was the name most popular\n",
    "name_peak_year = {};\n",
    "for name in name_year_frequency:\n",
    "    name_peak_year[name] = sorted(name_year_frequency[name].items(), key=lambda kv: kv[1])[::-1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for name in cool_names:\n",
    "    if name in name_year_frequency:\n",
    "        x, y = zip(*sorted(name_year_frequency[name].items()))\n",
    "        plt.plot(x, y, label=name)\n",
    "        plt.legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize a name by it's pronunciation\n",
    "def normalize_pronunciation(name):\n",
    "    if name.lower() in phonetic_dictionary:\n",
    "        return \"-\".join(phonetic_dictionary[name.lower()])\n",
    "    return \"-\"\n",
    "\n",
    "# Map names to their phonetic length\n",
    "name_length = {}\n",
    "for name in name_frequency:\n",
    "    if name.lower() in phonetic_dictionary:\n",
    "        name_length[name] = len(phonetic_dictionary[name.lower()])\n",
    "# sorted_name_length = sorted(name_length.items(), key=lambda kv: kv[1])[::-1]\n",
    "# sorted_name_length[:5]\n",
    "\n",
    "# Map a normalized name to its homonyms\n",
    "name_homonyms = {}\n",
    "for name in name_frequency:\n",
    "    normal = normalize_pronunciation(name)\n",
    "    if normal not in name_homonyms:\n",
    "        name_homonyms[normal] = [];\n",
    "    name_homonyms[normal].append(name)\n",
    "\n",
    "# Return True if there are no homonyms or if the given name is the\n",
    "# most popular among all known homonyms. This is useful for\n",
    "# filtering out unnecessary homonyms.\n",
    "def isMostFrequentHomonym(name):\n",
    "    if name_features[name]['homonym_count'] < 2:\n",
    "        return True\n",
    "    return (name == sorted(\n",
    "        name_features[name]['homonyms'],\n",
    "        key=lambda name: name_features[name]['popularity_rank']\n",
    "    )[0])\n",
    "\n",
    "# Names with most homonyms\n",
    "# sorted_name_homonym_count = sorted(name_homonyms.items(), key=lambda kv: len(kv[1]))[::-1]\n",
    "# sorted_name_homonym_count[1::][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_features = {};\n",
    "for name in name_frequency:\n",
    "    \n",
    "    homonyms = name_homonyms.get(normalize_pronunciation(name), []) if normalize_pronunciation(name) != '-' else []\n",
    "    min_homonym_female_ratio = min(\n",
    "        [1.0] + [item for item in map(lambda n: 1.0 * gender_name_frequency['F'].get(n, 0)/(gender_name_frequency['F'].get(n, 0) + gender_name_frequency['M'].get(n, 0)),\n",
    "            name_homonyms.get(normalize_pronunciation(name), []) \\\n",
    "                if normalize_pronunciation(name) != '-' else []\n",
    "        )]\n",
    "    )\n",
    "    max_homonym_female_ratio = max(\n",
    "        [0.0] + [item for item in map(lambda n: 1.0 * gender_name_frequency['F'].get(n, 0)/(gender_name_frequency['F'].get(n, 0) + gender_name_frequency['M'].get(n, 0)),\n",
    "            name_homonyms.get(normalize_pronunciation(name), []) \\\n",
    "                if normalize_pronunciation(name) != '-' else []\n",
    "        )]\n",
    "    )\n",
    "    \n",
    "    name_features[name] = {\n",
    "        'peak_year': name_peak_year.get(name, 0),\n",
    "        'phonetic': phonetic_dictionary.get(name.lower(), ''),\n",
    "        'phoneme_count': len(phonetic_dictionary.get(name.lower(), '')),\n",
    "        'homonyms': homonyms,\n",
    "        'homonym_count': len(homonyms),\n",
    "        'popularity_rank': name_rank.get(name, -1),\n",
    "        'female_ratio': 1.0 * gender_name_frequency['F'].get(name, 0) / (gender_name_frequency['F'].get(name, 0) + gender_name_frequency['M'].get(name, 0)),\n",
    "        'min_homonym_female_ratio': min_homonym_female_ratio,\n",
    "        'max_homonym_female_ratio': max_homonym_female_ratio,\n",
    "        'is_in_dictionary': name.lower() in english_dictionary,\n",
    "        'is_block_listed': name in block_list,\n",
    "        'is_reverse_in_dictionary': name.lower()[::-1] in english_dictionary,\n",
    "        'is_biblical_name': name in biblical_names,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: if we insist on having a phonetic spelling we'll miss out on names\n",
    "#          that aren't in the phonetic dictionary.\n",
    "\n",
    "criteria = lambda name, n: \\\n",
    "    not n['is_block_listed'] and \\\n",
    "    n['popularity_rank'] >= 0 and \\\n",
    "    n['popularity_rank'] <= 100000 and \\\n",
    "    n['peak_year'] >= 0 and n['peak_year'] <= 2009 and \\\n",
    "    n['homonym_count'] >= 0 and \\\n",
    "    n['female_ratio'] == 0.0 and \\\n",
    "    n['min_homonym_female_ratio'] >= 0.0 and n['max_homonym_female_ratio'] <= 0.0 and \\\n",
    "    n['phoneme_count'] > 0 and n['phoneme_count'] < 100 and \\\n",
    "    not n['is_biblical_name']\n",
    "#    n['phonetic'][-1] in {'V', 'Z'}\n",
    "#    n['phonetic'][-2:] == ['D', 'OW0']\n",
    "#    not n['is_in_english_dictionary'] and \\\n",
    "#    n['phonetic'][0] in {'D', 'M', 'N'} and \\\n",
    "\n",
    "list = [item for item in name_features.items() if criteria(item[0], item[1])]\n",
    "\n",
    "print(\"Matches: \" + str(len(list)))\n",
    "\n",
    "import random\n",
    "[item[0] for item in random.sample(list, min(10, len(list)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_peak_year = max(map(lambda p: p[1]['peak_year'], name_features.items()))\n",
    "min_peak_year = min(map(lambda p: p[1]['peak_year'], name_features.items()))\n",
    "max_popularity_rank = max(map(lambda p: p[1]['popularity_rank'], name_features.items()))\n",
    "max_phoneme_count = max(map(lambda p: p[1]['phoneme_count'], name_features.items()))\n",
    "max_homonym_count = max(map(lambda p: p[1]['homonym_count'], name_features.items()))\n",
    "\n",
    "weights = {\n",
    "    # Names that were most popular in 2018 get 1.0 and names that\n",
    "    # peaked in popularity in 1880 get a score of 0.0.\n",
    "    'peak_year_recency_ratio': 0.001,\n",
    "    \n",
    "    # 1.0 if the name peaked before 2010 or 0.0 if after.\n",
    "    'is_peak_year_before_2010': 0.00,\n",
    "\n",
    "    # 1.0 if the name peaked before 2005 or 0.0 if after.\n",
    "    'is_peak_year_before_2005': 0.00,\n",
    "\n",
    "    # 1.0 if the name peaked before 2000 or 0.0 if after.\n",
    "    'is_peak_year_before_2000': 0.0,\n",
    "\n",
    "    # 1.0 if the name peaked before 1982 or 0.0 if after.\n",
    "    'is_peak_year_before_1982': 0.00,\n",
    "\n",
    "    # 1.0 if the name peaked after 1948 or 0.0 if after.\n",
    "    'is_peak_year_after_1948': 0.01,\n",
    "\n",
    "    # The most popular name gets a score of 1.0 and the least 1.0.\n",
    "    'popularity_rank_ratio': 0.01,\n",
    "\n",
    "    # Names that aren't in the top n get a score of 1.0. Else 0.\n",
    "    'is_not_too_popular': 0.0,\n",
    "    \n",
    "    # Names that are in the top n get a score of 1.0. Else 0.\n",
    "    'is_popular_enough': 0.00,\n",
    "    \n",
    "    # Names that are only ever female get 1.0. Names that are only\n",
    "    # male get 0.0\n",
    "    'female_ratio': 0.0,\n",
    "    \n",
    "    # Names get 1.0 if they are less than 25% female, else 0.\n",
    "    'female_ratio_cutoff_20': 0.01,\n",
    "    \n",
    "    # The maximum `female_ratio` score across all homonyms\n",
    "    'max_homonym_female_ratio': 0.0,\n",
    "    \n",
    "    # The minimum `female_ratio` score across all homonyms\n",
    "    'min_homonym_female_ratio': 0.0,\n",
    "    \n",
    "    # 1.0 if the name is block listed, else 0.0.\n",
    "    'is_block_listed': -1.0,\n",
    "    \n",
    "    # 1.0 if the name is in the English dictionary, else 0.0\n",
    "    'is_in_dictionary': 0.0,\n",
    "    \n",
    "    # 1.0 if the reverse of the name is in the English dictionary\n",
    "    'is_reverse_in_dictionary': 0.0,\n",
    "    \n",
    "    # 1.0 if the name is in the phonetic dictionary\n",
    "    'is_in_phonetic_dictionary': 0.0,\n",
    "    \n",
    "    # 1.0 if the name has the most phonemes\n",
    "    'phoneme_count_ratio': 0.0,\n",
    "    \n",
    "    # 1.0 if the name has the most homonyms\n",
    "    'homonym_count_ratio': 0.0,\n",
    "    \n",
    "    # 1.0 if the name is in a dictionary of biblical names, else 0\n",
    "    'is_biblical_name': -0.2,\n",
    "    \n",
    "    'is_most_frequent_homonym': 1.0,\n",
    "}\n",
    "\n",
    "name_vector = {name: {\n",
    "    'peak_year_recency_ratio': 1.0 - (1.0 * (max_peak_year - v['peak_year']) / min_peak_year),\n",
    "    'is_peak_year_before_2010': 1.0 if v['peak_year'] < 2010 else 0.0,\n",
    "    'is_peak_year_before_2005': 1.0 if v['peak_year'] < 2005 else 0.0,    \n",
    "    'is_peak_year_before_2000': 1.0 if v['peak_year'] < 2000 else 0.0,    \n",
    "    'is_peak_year_before_1982': 1.0 if v['peak_year'] < 1982 else 0.0,\n",
    "    'is_peak_year_after_1948': 1.0 if v['peak_year'] > 1948 else 0.0,\n",
    "    'popularity_rank_ratio': 1.0 - (1.0 * v['popularity_rank'] / max_popularity_rank),\n",
    "    'is_not_too_popular': 1.0 if v['popularity_rank'] >= 400 else 0,\n",
    "    'is_popular_enough': 1.0 if v['popularity_rank'] < 600 else 0,\n",
    "    'female_ratio': v['female_ratio'],\n",
    "    'female_ratio_cutoff_20': 1.0 if v['female_ratio'] <= 0.20 else 0.0,\n",
    "    'max_homonym_female_ratio': v['max_homonym_female_ratio'],\n",
    "    'min_homonym_female_ratio': v['min_homonym_female_ratio'],\n",
    "    'is_block_listed': 1.0 if v['is_block_listed'] else 0.0,\n",
    "    'is_in_dictionary': 1.0 if v['is_in_dictionary'] else 0.0,\n",
    "    'is_reverse_in_dictionary': 1.0 if v['is_reverse_in_dictionary'] else 0.0,\n",
    "    'is_in_phonetic_dictionary': 1.0 if not v['phoneme_count'] else 0.0,\n",
    "    'phoneme_count_ratio': (1.0 * v['phoneme_count'] / max_phoneme_count),\n",
    "    'homonym_count_ratio': (1.0 * v['homonym_count'] / max_homonym_count),\n",
    "    'is_biblical_name': 1.0 if v['is_biblical_name'] else 0.0,\n",
    "    'is_most_frequent_homonym': 1.0 if isMostFrequentHomonym(name) else 0.0,\n",
    "} for name, v in name_features.items()}\n",
    "\n",
    "from functools import reduce\n",
    "def score(name):\n",
    "    return reduce(\n",
    "        lambda s, feature: \\\n",
    "            s + (weights[feature] * name_vector[name][feature]),\n",
    "        weights.keys(),\n",
    "        0.0\n",
    "    )\n",
    "\n",
    "from random import sample\n",
    "names = sorted(sample(name_vector.items(), len(name_vector.items())), key=lambda kv: score(kv[0]))[::-1]\n",
    "\n",
    "# Filter out the least popular homonyms.\n",
    "for name in [name[0] for name in filter(lambda kv: isMostFrequentHomonym(kv[0]), names)][:1000]:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(\n",
    "    [t[0] for t in enumerate(names)][:1000],\n",
    "    [score(t[1][0]) for t in enumerate(names)][:1000],\n",
    "    label=score\n",
    ")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_features['Moss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for name in [name[0] for name in names[:10]]:\n",
    "    if name in name_year_frequency:\n",
    "        x, y = zip(*sorted(name_year_frequency[name].items()))\n",
    "        plt.plot(x, y, label=name)\n",
    "        plt.legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data\n",
    "ratings = {}\n",
    "with open(\"./name_ratings.tsv\") as file:\n",
    "    for line in file:\n",
    "        columns = line.split(\"\\t\")\n",
    "        ratings[columns[0]] = {\n",
    "            'Hannah': columns[1],\n",
    "            'Andrew': columns[2]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "samples = {\n",
    "    'Andrew': 1.0,\n",
    "    'Hannah': 1.0,\n",
    "    'Jim': 0.0,\n",
    "    'Van': 0.0,\n",
    "}\n",
    "\n",
    "# x-coordinates of our samples\n",
    "x = [x for x in dict.keys(samples)]\n",
    "\n",
    "# y-coordinates of our samples\n",
    "y = [y for y in dict.values(samples)]\n",
    "\n",
    "# Degree of our polynomial\n",
    "deg = sum(1 for line in dict.keys(weights))\n",
    "\n",
    "\n",
    "np.polyfit(x, y, deg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy.polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False)[source]\n",
    "Least squares polynomial fit.\n",
    "\n",
    "Fit a polynomial p(x) = p[0] * x^deg + ... + p[deg] of degree deg to points (x, y). Returns a vector of coefficients p that minimises the squared error.\n",
    "\n",
    "## Parameters:\t\n",
    "\n",
    "x : array_like, shape (M,)\n",
    "x-coordinates of the M sample points (x[i], y[i]).\n",
    "\n",
    "y : array_like, shape (M,) or (M, K)\n",
    "y-coordinates of the sample points. Several data sets of sample points sharing the same x-coordinates can be fitted at once by passing in a 2D-array that contains one dataset per column.\n",
    "\n",
    "deg : int\n",
    "Degree of the fitting polynomial\n",
    "\n",
    "rcond : float, optional\n",
    "Relative condition number of the fit. Singular values smaller than this relative to the largest singular value will be ignored. The default value is len(x)*eps, where eps is the relative precision of the float type, about 2e-16 in most cases.\n",
    "\n",
    "full : bool, optional\n",
    "Switch determining nature of return value. When it is False (the default) just the coefficients are returned, when True diagnostic information from the singular value decomposition is also returned.\n",
    "\n",
    "w : array_like, shape (M,), optional\n",
    "Weights to apply to the y-coordinates of the sample points. For gaussian uncertainties, use 1/sigma (not 1/sigma**2).\n",
    "\n",
    "cov : bool, optional\n",
    "Return the estimate and the covariance matrix of the estimate If full is True, then cov is not returned.\n",
    "Returns:\t\n",
    "\n",
    "p : ndarray, shape (deg + 1,) or (deg + 1, K)\n",
    "Polynomial coefficients, highest power first. If y was 2-D, the coefficients for k-th data set are in p[:,k].\n",
    "residuals, rank, singular_values, rcond\n",
    "Present only if full = True. Residuals of the least-squares fit, the effective rank of the scaled Vandermonde coefficient matrix, its singular values, and the specified value of rcond. For more details, see linalg.lstsq.\n",
    "\n",
    "V : ndarray, shape (M,M) or (M,M,K)\n",
    "Present only if full = False and cov`=True. The covariance matrix of the polynomial coefficient estimates. The diagonal of this matrix are the variance estimates for each coefficient. If y is a 2-D array, then the covariance matrix for the `k-th data set are in \n",
    "V[:,:,k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
